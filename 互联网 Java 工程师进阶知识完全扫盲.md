# 高并发架构

## 消息队列

### 为什么使用消息队列

#### 使用场景

##### 解耦

场景：

A系统调用BCD三个系统的接口，如果B系统不需要接收数据了呢？如果又有新系统E需要这份数据呢。并且需要考虑BCDE系统挂了怎么办，是用重发解决还是把消息存起来?

**使用MQ进行解耦**

A系统将消息发送到MQ，BCDE系统谁需要这份消息就去订阅进行消费，这样就进行解耦了。

**总结**

通过一个MQ，PUB/SUB 发布订阅消息这一个模型，A系统就和其它系统进行解耦了。

##### 异步

场景：

A系统接受请求->A系统写库->B系统写库->C系统写库->D系统写库

总共耗时=A系统10ms+B系统200ms+C系统300ms+D系统300ms=810ms

如何优化这个请求耗时降到200ms以内？

**使用MQ进行削峰**

A系统接受请求->向MQ中发送三条消息以供BCD系统进行消费

总共耗时=A系统原本耗时10ms+三条消息入队列耗时10ms=20ms

##### 削峰

场景：

系统在高峰期涌入过量请求，这些请求会涌入MySQL,导致MySQL抗不住然后系统崩溃。

假设每秒钟

5K请求->一秒内支持2K请求的系统->系统崩溃

**使用MQ进行削峰**

5K请求->写入MQ->系统每秒从MQ拉取2K条消息进行消费->MySQL落库

#### 优缺点	

##### 优点

解耦 异步 削峰

##### 缺点

**系统可用性降低**

MQ一挂整套系统崩溃

**系统复杂度提高**

加个MQ进来，会导致可能出现的问题：重复消费，消息丢失，消息传递的顺序性

**一致性问题**

之前异步的处理方案，BC系统消费完写库成功，D系统失败，这就导致了一致性问题。

#### 技术选型

**中小型公司**技术实力较为一般，项目技术挑战不是特别高，用RabbitMQ是不错的选择

**大型公司**基础架构研发实力较强，用RocketMQ是很好的选择。

**大型数据领域**的实时计算,日志采集系统，用Kafka是业内标准的，几乎是全世界这个领域的事实性规范。

### 如何保证消息队列的高可用

#### RabbitMQ

基于主从（非分布式）做高可用性

##### 单机模式（无高可用）

demo级别，没人在生产用单机模式。

##### 普通集群模式（无高可用）

没做到分布式，就是个普通集群，没有高可用性，这个方案能提高吞吐量。

##### 镜像集群模式

元数据和queue里的消息都会存在于多个RabbitMQ节点上。

缺点：

1.性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重。

2.不是分布式的，没有扩展性可言。

#### Kafka

Kafka架构->多个broker组成->每个broker是一个节点(一台服务器)

topic->划分多个partition->每个partition存放一部分数据->存放于一个broker上

**天然的分布式消息队列**

一个topic分散存放在多个机器上。

##### 高可用(HA机制)

每个partition->有多个replica副本在不同的机器上->所有replica选举出一个leader（生产和消费都跟这个leader打交道)->其他replica就是follower

**为何只能读写leader?**

要是可以允许随意读写每一个follower，就会产生数据一致性的问题，系统复杂度太高。

### 如何保证消息不被重复消费

本质上是

**使用消息队列如何保证幂等性**

都得结合业务思考，举几个例子：

1.有一条消息要写库，先根据主键查询，如果这数据有了，就直接丢弃或者更新。

2.写redis，每次都是set，天然幂等性

3.基于数据库的主键约束来避免重复消费

### 如何保证消息的可靠性传输

##### RabbitMQ

###### 生产者

生产者向RabbitMQ发送数据的时候，因为网络问题丢失了数据。

**解决方案**

生产者开启异步confirm模式->消息先落库->发送消息->RabbitMQ会给你回传一个ack消息->将落库的消息打标记为已经发送成功

定时任务->抓取未发送状态并且创建时间大于一定范围的消息->重新进行消息发送->超过3次未发送成功则标记发送失败

###### RabbitMQ

消息存在于内存中，还没有消费掉，RabbitMQ挂掉了导致消息丢失。

**解决方案**

**开启RabbitMQ的持久化**

1.创建queue的时候将其设置为持久化，这样就可以保证持久化queue的元数据。

2.发送消息的时候将消息的deliveryMode(投递模式)设置为2，也就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上。

**优化点**

持久化跟生产者的confirm机制配合起来，只有消息被持久化到磁盘后，才会通知生产者ack了。

###### 消费者

刚消费到，还没处理，结果进程挂了，比如重启。

**解决方案**

**关闭RabbitMQ的自动ack**，在代码中消费完消息，处理完业务，再去ack一把。

##### Kafka

###### 生产者

按照下面第3,4点设置，一定不会丢。

###### Kafka

某个broker(leader)宕机=>其他follower还未同步数据=>重新选举leader=>消息数据丢失

**解决方案**

1. topic设置 replication.factor>1，要求每个partition至少有2个副本。

2. 服务端设置min.insync.replicas>1，要求leader感知至少一个follower跟自己保持联系。

3. producer端设置acks=all，要求每条数据写入所有replica之后，才能认为是写成功了。

4. producer端设置retries=MAX(很大的值)，一旦写入失败，无限重试。

###### 消费者

刚消费这个消息，还没处理完，**自动提交了offset**，然后挂掉了。（同RabbitMQ差不多）

**解决方案**

**关闭自动提交offset**

### 如何保证消息的顺序性

在一些场景下，需要保证传入消息队列的消息按顺序消费。

#### RabbitMQ

##### 错乱场景

一个queue=>生产者发送三条数据data1，data2，data3(期望消费顺序1，2,3)=>三个消费者消费顺序data2，data1，data3

##### 解决方案

拆分多个queue=>每个queue对应一个消费者=>data1，data2，data3按顺序传入同一个队列=>消费者内部可以采用单线程消费

#### Kafka

topic=>

##### 错乱场景

##### 解决方案

