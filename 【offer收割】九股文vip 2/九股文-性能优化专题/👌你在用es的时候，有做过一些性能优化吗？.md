[![16、在用es的时候，有进行过一些调优吗.mp4 (22.97MB)](https://gw.alipayobjects.com/mdn/prod_resou/afts/img/A*NNs6TKOR3isAAAAAAAAAAABkARQnAQ)](https://www.yuque.com/docs/176645986?_lake_card=%7B%22status%22%3A%22done%22%2C%22name%22%3A%2216%E3%80%81%E5%9C%A8%E7%94%A8es%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E6%9C%89%E8%BF%9B%E8%A1%8C%E8%BF%87%E4%B8%80%E4%BA%9B%E8%B0%83%E4%BC%98%E5%90%97.mp4%22%2C%22size%22%3A24084572%2C%22taskId%22%3A%22u803fa7ee-dbaa-4b71-9d02-5b44447e5af%22%2C%22taskType%22%3A%22upload%22%2C%22url%22%3Anull%2C%22cover%22%3Anull%2C%22videoId%22%3A%22inputs%2Fprod%2Fyuque%2F2024%2F29413969%2Fmp4%2F1719845533156-d736678e-d7e2-4449-b7ad-34b0083ac41c.mp4%22%2C%22download%22%3Afalse%2C%22__spacing%22%3A%22both%22%2C%22id%22%3A%22XoNOO%22%2C%22margin%22%3A%7B%22top%22%3Atrue%2C%22bottom%22%3Atrue%7D%2C%22card%22%3A%22video%22%7D#XoNOO)本性能优化案例是通用的！大家消化完成，直接套到自己项目即可！<br />本题配备了视频助于理解。<br />这道题其实主要还是拔高的，将 es 和 jvm 做了一波匹配。
# 口语化回答
有的，面试官，我们项目里有个场景是查询街道的地址，也就是平时寄快递的时候，那种场景。这个主要是走的我们的 es 的集群。由于这个接口的请求量非常大，1 天大概要发生 3000 多次 young gc，整体要消耗 20s，这确实是非常影响性能的。我主要是通过排查 gc 的日志，发现每次产生 gc 都是由于内存分配失败，产生了 ygc，进而观察日志的，堆分配空间是 40g，而 young 区才 1g。由于像地址这种特性都是模糊查询，于是会造成 es 产生大量临时中间数据，eden 区就会产生大量的使用。于是我就直接将 young 区调整到 10g。观察后，效果非常好，一天才发生 20 次 gc，整体耗时 1s。
# 背景
先给大家说一下结果。1天从3000多次的ygc，优化到20次ygc。整体的ygc耗时从最高的20s到1s。整体指标的提升非常好看。优化后，可用率有时降低的问题也已经解决。<br />再来说一下我们的背景，我们有这样一个业务场景，查询街道地址地图的一个借口，就是你平时快递填地址的数据。整体的信息量很大，我们基于es做为数据源进行存储。这个借口的ygc问题，一直也都存在，我们尝试过，单独给他一个es集群，避免索引间共享的互相影响，还做了缓存，es集群的硬件也扩容过。整体上性能确实有好一些，但还是会存在ygc频繁导致的可用率降低问题。于是，最近再次发生，又开启了一波排查之旅。
# 排查过程
在发生可用率降低的那一刻，看了一眼监控，果然还是突发频繁的fullgc。但是看了一眼堆内存，虽然发生频繁的gc，内存却一点都没有下降。导致这种情况一般有可能是2个原因，一是新生代在GC的时候存活率很高，YGC发生时存活对象的回收阈值在不断+1，最后存活对象被不断转移到老年代，所以整体没多大起伏，但是看了一下FGC的次数，该时间段内为0，所以这种可能性不大，因为如果是这样的话，随着存活对象转移和新对象的创建，整体使用率是会上升的。还有一种可能就是young区在堆中占比很小，YGC所清理出来的空间和老年代比起来不值得一提。<br />然后就开始看起了gc日志，发现这个时间段内确实触发了多次因内存分配失败而导致的YGC。日志里面打印出了很多allocation failure。我们的堆区的分配空间是32395136K 也就是30.9G，而young区为996800K也就是0.95G。<br />因为es的查询大部分都是模糊查询，所以在查询的时候可能会生成大量的临时中间数据，所以对Eden区的使用是比较高的，因为并发数也比较高，所以TLAB分配的空间也不少，所以在遇到某些查询匹配到的数据比较大时，或者应用的QPS较高时都会出现这种频繁YGC的情况。那优化方案也很明显，就是调整JVM的参数就可以了，观察了一下整体，机器是64g的。现在才32g的堆，提高到百分之70，堆内存设置为40g。多的8g直接分配给新生代，既然比较频繁，索性到10g吧。调整完后，性能贼好。
